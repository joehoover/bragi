{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generating metered verse with LLaMA\n",
    "\n",
    "This notebook demonstrates how to use Meta's 6 billion parameter LLaMA model to generate song lyrics with a specific metric structure. If you've been yearning to rewrite the happy birthday song so that it's just about dogs, `MetricGenerator` can help :). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook relies on the `MetricGenerator` class implemented my [bragi](https://github.com/joehoover/bragi) repository. If you're wondering, Bragi (pictured below) is the [Norse god](https://en.wikipedia.org/wiki/Bragi) of poetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Bragi_by_Wahlbom.jpg/440px-Bragi_by_Wahlbom.jpg\" width=\"150\" height=\"150\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"http://my_site.com/my_picture.jpg\")\n",
    "Image(url= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Bragi_by_Wahlbom.jpg/440px-Bragi_by_Wahlbom.jpg\", width=150, height=150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The `MetricGenerator` class allows you to specify an *initialization* song that is used to specify a target metric structure. Then, given this target metric structure, it attempts to generate new lyrics with the same metric structure. \n",
    "\n",
    "For example, the following lines\n",
    "\n",
    "<blockquote>\n",
    "Happy birthday to you<br>\n",
    "Happy birthday to you<br>\n",
    "Happy birthday dear Marvin<br>\n",
    "Happy birthday to you\n",
    "</blockquote>\n",
    "\n",
    "have 6, 6, 7, and 6 syllables respectively. With `MetricGenerator`, you can use those lyrics to initialize a metric structure and then generate new lyrics with the same metric structure.\n",
    "\n",
    "And, most importantly, you can guide the new lyrics with a prompt!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Quick demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check it out! First, we'll load our dependencies, specify some paths, and initialize a model and tokenizer.\n",
    "\n",
    "For this demo, I'll use Meta's 6 billion parameter `LLaMA` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bragi.metric_generator import MetricGenerator\n",
    "from transformers import LLaMAForCausalLM, LLaMATokenizer\n",
    "import torch \n",
    "\n",
    "CACHE_DIR = 'weights'\n",
    "SEP = \"<sep>\"\n",
    "MODEL_PATH  = \"/src/weights\"\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "model = LLaMAForCausalLM.from_pretrained(MODEL_PATH, cache_dir=CACHE_DIR, local_files_only=True).to(device)\n",
    "tokenizer = LLaMATokenizer.from_pretrained(MODEL_PATH, cache_dir=CACHE_DIR, local_files_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll initialize the metric generator class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = MetricGenerator(model=model, tokenizer=tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate lyrics, you just need to provide a prompt and the lyrics you want to use to initialize your metric structure. Let's try the happy birthday song displayed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy birthday to you,\n",
      "Happy birthday to you,\n",
      "Happy birthday dear Marvin,\n",
      "Happy birthday to you\n"
     ]
    }
   ],
   "source": [
    "text_init = \"Happy birthday to you,\\nHappy birthday to you,\\nHappy birthday dear Marvin,\\nHappy birthday to you\"\n",
    "print(text_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's try to generate a new song that has the same metric structure, but is about dogs. To do that, we can use something like the following prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a song about dogs:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"This is a song about dogs:\\n\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can call our `MetricGenerator` instance. The `__call__` method of `MetricGenerator` accepts all of the arguments that `Transformers.model.generate()` does, but it adds a few extra methods that allow us to constrain the generation process so that the target metric structure is respected.\n",
    "\n",
    "**Note:** If you want the raw token_ids, you can call `MetricGenerator.generate()` with the same arguments. In contrast, `MetricGenerator.__call__()` returns the decoded output string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---text_init----\n",
      "Happy birthday to you,\n",
      "Happy birthday to you,\n",
      "Happy birthday dear Marvin,\n",
      "Happy birthday to you\n",
      "\n",
      "\n",
      "----output-----\n",
      "I love how the dogs can \n",
      "be so good, so bad, and \n",
      "so strange. Sometimes I love them \n",
      "when they are the most good\n",
      "\n",
      "\n",
      "----Syllables-----\n",
      "Syllables per line in output: tensor([6., 6., 7., 6.])\n",
      "Syllables per line in `text_init`: tensor([6., 6., 7., 6.])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2)\n",
    "output = generator(\n",
    "    prompt = prompt,\n",
    "    text_init = text_init,\n",
    "    free_tokens=['||', '?', '.', ','],\n",
    "    # syllable_budget = torch.Tensor([6., 6.]),\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=2,\n",
    "    remove_invalid_values=True,\n",
    "    do_sample=True,\n",
    "    top_k=25,\n",
    "    temperature=.7,\n",
    "    max_length = 100,\n",
    "    new_line_token='||',\n",
    "    bad_words_ids=[[8876]],\n",
    ")\n",
    "\n",
    "print('---text_init----')\n",
    "print(text_init)\n",
    "print('\\n')\n",
    "\n",
    "print('----output-----')\n",
    "print(output)\n",
    "print('\\n')\n",
    "\n",
    "print('----Syllables-----')\n",
    "print(f\"Syllables per line in output: {generator.calculate_syllable_budget(output)}\")\n",
    "print(f\"Syllables per line in `text_init`: {generator.calculate_syllable_budget(text_init)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat! We rewrote happy birthday to be aboud dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the effect of prompt conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some other prompts and see how responsive the model is to prompt conditioning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **California ☀️!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_init = \"Happy birthday to you,\\nHappy birthday to you,\\nHappy birthday dear Marvin,\\nHappy birthday to you\"\n",
    "prompt = \"\"\"This is a song about about California sun:\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---prompt---\n",
      "This is a song about about California sun:\n",
      "\n",
      "\n",
      "---text_init----\n",
      "Happy birthday to you,\n",
      "Happy birthday to you,\n",
      "Happy birthday dear Marvin,\n",
      "Happy birthday to you\n",
      "\n",
      "\n",
      "----output-----\n",
      "I love how the colors \n",
      "the lights are bright, the air \n",
      "is warm and the water is \n",
      "clear. I love the way the\n",
      "\n",
      "\n",
      "----Syllables-----\n",
      "Syllables per line in output: tensor([6., 6., 7., 6.])\n",
      "Syllables per line in `text_init`: tensor([6., 6., 7., 6.])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2)\n",
    "output = generator(\n",
    "    prompt = prompt,\n",
    "    text_init = text_init,\n",
    "    # syllable_budget = torch.Tensor([6., 6.]),\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=2,\n",
    "    remove_invalid_values=True,\n",
    "    do_sample=True,\n",
    "    top_k=25,\n",
    "    temperature=.7,\n",
    "    max_length = 100,\n",
    "    new_line_token='||',\n",
    "    free_tokens=['||', '?', '.', ','], \n",
    "    bad_words_ids=[[8876]],\n",
    ")\n",
    "\n",
    "print('---prompt---')\n",
    "print(prompt.strip())\n",
    "print('\\n')\n",
    "\n",
    "print('---text_init----')\n",
    "print(text_init)\n",
    "print('\\n')\n",
    "\n",
    "print('----output-----')\n",
    "print(output)\n",
    "print('\\n')\n",
    "\n",
    "print('----Syllables-----')\n",
    "print(f\"Syllables per line in output: {generator.calculate_syllable_budget(output)}\")\n",
    "print(f\"Syllables per line in `text_init`: {generator.calculate_syllable_budget(text_init)}\")\n",
    "# print(tokenizer.decode(output[0], skip_special_tokens=True).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dark and stormy 🌊**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_init = \"Happy birthday to you,\\nHappy birthday to you,\\nHappy birthday dear Marvin,\\nHappy birthday to you\"\n",
    "prompt = \"\"\"This a beautiful poem that uses descriptive, earthy language to describe the ocean during a storm:\\n\\\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---prompt---\n",
      "This a beautiful poem that uses descriptive, earthy language to describe the ocean during a storm:\n",
      "\"\n",
      "\n",
      "\n",
      "---text_init----\n",
      "Happy birthday to you,\n",
      "Happy birthday to you,\n",
      "Happy birthday dear Marvin,\n",
      "Happy birthday to you\n",
      "\n",
      "\n",
      "----output-----\n",
      "In the storm, the wind and \n",
      "the sea are one. The waves \n",
      "are the breath of the gods. As \n",
      "they break and fall back, they\n",
      "\n",
      "\n",
      "----Syllables-----\n",
      "Syllables per line in output: [6, 6, 7, 6]\n",
      "Syllables per line in `text_init`: [6, 6, 7, 6]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(5)\n",
    "output = generator(\n",
    "    prompt = prompt,\n",
    "    text_init = text_init,\n",
    "    # syllable_budget = torch.Tensor([6., 6.]),\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=2,\n",
    "    remove_invalid_values=True,\n",
    "    do_sample=True,\n",
    "    top_k=25,\n",
    "    temperature=.7,\n",
    "    max_length = 100,\n",
    "    new_line_token='||',\n",
    "    free_tokens=['||', '?', '.', ','], \n",
    "    bad_words_ids=[[8876]],\n",
    ")\n",
    "\n",
    "print('---prompt---')\n",
    "print(prompt.strip())\n",
    "print('\\n')\n",
    "\n",
    "print('---text_init----')\n",
    "print(text_init)\n",
    "print('\\n')\n",
    "\n",
    "print('----output-----')\n",
    "print(output)\n",
    "print('\\n')\n",
    "\n",
    "print('----Syllables-----')\n",
    "print(f\"Syllables per line in output: {generator.calculate_syllable_budget(output, pt=False)}\")\n",
    "print(f\"Syllables per line in `text_init`: {generator.calculate_syllable_budget(text_init, pt=False)}\")\n",
    "# print(tokenizer.decode(output[0], skip_special_tokens=True).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've seen `MetricGenerator` in action, let's take a peak under the hood. We'll discuss:\n",
    "\n",
    "1. How `MetricGenerator` constrains generation\n",
    "2. The fact that it occasionally violates the target metric structure\n",
    "3. Shortcomings of the current implementation\n",
    "4. Ways that we could improve `MetricGenerator` and shortcomings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does `MetricGenerator` constrain generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MetricGenerator` uses a logit warper to constrain model vocabulary during the generation process. A logit warper is a callable that modifies a model's probability distribution over tokens during generation. Specifically, `MetricGenerator` uses the `SyllableRestrictionWarper`, which is implemented in `bragi.logit_warpers`. \n",
    "\n",
    "The `SyllableRestrictionWarper` constrains the metric structure of model generated output by tracking a line-level metric *budget* and a number-of-lines budget. Every time the generator *spends* one more more syllables, the budget is decremented. When all of the syllables permitted for a given line are spent, the warper forces a new line token by setting the logit scores for all other tokens to `-Inf`. Further, when a new line token is emitted, the number-of-lines budget is decremented by one. Finally, when the number-of-lines budget reaches zero, the warper forces the eos token using the same approach. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating syllable cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = MetricGenerator(model=model, tokenizer=tokenizer, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A song about dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---text_init----\n",
      "Happy birthday to you,\n",
      "Happy birthday to you,\n",
      "Happy birthday dear Marvin,\n",
      "Happy birthday to you\n",
      "\n",
      "\n",
      "----output-----\n",
      "I love how the dogs can \n",
      "be so good, so bad, and \n",
      "so strange. Sometimes I love them \n",
      "when they are the most good\n",
      "\n",
      "\n",
      "----Syllables-----\n",
      "Syllables per line in output: tensor([6., 6., 7., 6.])\n",
      "Syllables per line in `text_init`: tensor([6., 6., 7., 6.])\n"
     ]
    }
   ],
   "source": [
    "text_init = \"Happy birthday to you,\\nHappy birthday to you,\\nHappy birthday dear Marvin,\\nHappy birthday to you\"\n",
    "prompt = \"\"\"This is a song about dogs:\\n\"\"\"\n",
    "torch.manual_seed(2)\n",
    "output = generator.generate(\n",
    "    prompt = prompt,\n",
    "    text_init = text_init,\n",
    "    # syllable_budget = torch.Tensor([6., 6.]),\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=2,\n",
    "    remove_invalid_values=True,\n",
    "    do_sample=True,\n",
    "    top_k=25,\n",
    "    temperature=.7,\n",
    "    max_length = 100,\n",
    "    new_line_token='||',\n",
    "    free_tokens=['||', '?', '.', ','], \n",
    "    bad_words_ids=[[8876]],\n",
    ")\n",
    "\n",
    "print('---text_init----')\n",
    "print(text_init)\n",
    "print('\\n')\n",
    "\n",
    "print('----output-----')\n",
    "print(output)\n",
    "print('\\n')\n",
    "\n",
    "print('----Syllables-----')\n",
    "print(f\"Syllables per line in output: {generator.calculate_syllable_budget(output)}\")\n",
    "print(f\"Syllables per line in `text_init`: {generator.calculate_syllable_budget(text_init)}\")\n",
    "# print(tokenizer.decode(output[0], skip_special_tokens=True).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---prompt---\n",
      "This is a song about about California sun:\n",
      "\n",
      "\n",
      "---text_init----\n",
      "Happy birthday to you,\n",
      "Happy birthday to you,\n",
      "Happy birthday dear Marvin,\n",
      "Happy birthday to you\n",
      "\n",
      "\n",
      "----output-----\n",
      "I love how the colors \n",
      "the lights are bright, the air \n",
      "is warm and the water is \n",
      "clear. I love the way the\n",
      "\n",
      "\n",
      "----Syllables-----\n",
      "Syllables per line in output: tensor([6., 6., 7., 6.])\n",
      "Syllables per line in `text_init`: tensor([6., 6., 7., 6.])\n"
     ]
    }
   ],
   "source": [
    "text_init = \"Happy birthday to you,\\nHappy birthday to you,\\nHappy birthday dear Marvin,\\nHappy birthday to you\"\n",
    "prompt = \"\"\"This is a song about about California sun:\\n\"\"\"\n",
    "torch.manual_seed(2)\n",
    "output = generator.generate(\n",
    "    prompt = prompt,\n",
    "    text_init = text_init,\n",
    "    # syllable_budget = torch.Tensor([6., 6.]),\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=2,\n",
    "    remove_invalid_values=True,\n",
    "    do_sample=True,\n",
    "    top_k=25,\n",
    "    temperature=.7,\n",
    "    max_length = 100,\n",
    "    new_line_token='||',\n",
    "    free_tokens=['||', '?', '.', ','], \n",
    "    bad_words_ids=[[8876]],\n",
    ")\n",
    "\n",
    "print('---prompt---')\n",
    "print(prompt.strip())\n",
    "print('\\n')\n",
    "\n",
    "print('---text_init----')\n",
    "print(text_init)\n",
    "print('\\n')\n",
    "\n",
    "print('----output-----')\n",
    "print(output)\n",
    "print('\\n')\n",
    "\n",
    "print('----Syllables-----')\n",
    "print(f\"Syllables per line in output: {generator.calculate_syllable_budget(output)}\")\n",
    "print(f\"Syllables per line in `text_init`: {generator.calculate_syllable_budget(text_init)}\")\n",
    "# print(tokenizer.decode(output[0], skip_special_tokens=True).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---prompt---\n",
      "This a beautiful poem that uses descriptive, earthy language to describe the ocean during a storm:\n",
      "\"\n",
      "\n",
      "\n",
      "---text_init----\n",
      "Happy birthday to you,\n",
      "Happy birthday to you,\n",
      "Happy birthday dear Marvin,\n",
      "Happy birthday to you\n",
      "\n",
      "\n",
      "----output-----\n",
      "In the storm, the wind and \n",
      "the sea are one. The waves \n",
      "are the breath of the gods. As \n",
      "they break and fall back, they\n",
      "\n",
      "\n",
      "----Syllables-----\n",
      "Syllables per line in output: [6, 6, 7, 6]\n",
      "Syllables per line in `text_init`: [6, 6, 7, 6]\n"
     ]
    }
   ],
   "source": [
    "text_init = \"Happy birthday to you,\\nHappy birthday to you,\\nHappy birthday dear Marvin,\\nHappy birthday to you\"\n",
    "prompt = \"\"\"This a beautiful poem that uses descriptive, earthy language to describe the ocean during a storm:\\n\\\"\"\"\"\n",
    "torch.manual_seed(5)\n",
    "output = generator.generate(\n",
    "    prompt = prompt,\n",
    "    text_init = text_init,\n",
    "    # syllable_budget = torch.Tensor([6., 6.]),\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=2,\n",
    "    remove_invalid_values=True,\n",
    "    do_sample=True,\n",
    "    top_k=25,\n",
    "    temperature=.7,\n",
    "    max_length = 100,\n",
    "    new_line_token='||',\n",
    "    free_tokens=['||', '?', '.', ','], \n",
    "    bad_words_ids=[[8876]],\n",
    ")\n",
    "\n",
    "print('---prompt---')\n",
    "print(prompt.strip())\n",
    "print('\\n')\n",
    "\n",
    "print('---text_init----')\n",
    "print(text_init)\n",
    "print('\\n')\n",
    "\n",
    "print('----output-----')\n",
    "print(output)\n",
    "print('\\n')\n",
    "\n",
    "print('----Syllables-----')\n",
    "print(f\"Syllables per line in output: {generator.calculate_syllable_budget(output, pt=False)}\")\n",
    "print(f\"Syllables per line in `text_init`: {generator.calculate_syllable_budget(text_init, pt=False)}\")\n",
    "# print(tokenizer.decode(output[0], skip_special_tokens=True).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Deviations from specified meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /root/.pyenv/versions/3.10.10/lib/python3.10/site-packages (4.65.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [05:01<00:00,  3.02s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "prompt = \"\"\"This a beautiful poem that uses descriptive, earthy language to describe the ocean during a storm:\\n\\\"\"\"\"\n",
    "text_init = \"Happy birthday to you,\\nHappy birthday to you,\\nHappy birthday dear Marvin,\\nHappy birthday to you\"\n",
    "init_syllables = generator.calculate_syllable_budget(text_init)\n",
    "\n",
    "output_syllables = []\n",
    "for i in tqdm.tqdm(range(0, 100)):\n",
    "    output = generator.generate(\n",
    "        prompt = prompt,\n",
    "        text_init = text_init,\n",
    "        # syllable_budget = torch.Tensor([6., 6.]),\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        remove_invalid_values=True,\n",
    "        do_sample=True,\n",
    "        top_k=25,\n",
    "        temperature=.7,\n",
    "        max_length = 100,\n",
    "        new_line_token='||',\n",
    "        free_tokens=['||', '?', '.', ','], \n",
    "        bad_words_ids=[[8876]],\n",
    "    )\n",
    "    \n",
    "    output_syllables.append(generator.calculate_syllable_budget(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacked_output_syllables = torch.stack(output_syllables)\n",
    "deviation = stacked_output_syllables - init_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average line-level violation of the metric constraint is -0.5174999833106995,       which suggests that the mechanism is unbiased but still flawed.\n",
      "The vast majority of deviations are within +/- 1.824031949043274 syllables of the constraint.\n"
     ]
    }
   ],
   "source": [
    "m = deviation.mean()\n",
    "std = deviation.std()\n",
    "\n",
    "print(f\"The average line-level violation of the metric constraint is {m}.\")\n",
    "print(f\"The vast majority of deviations are within +/- {std*2} syllables of the constraint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

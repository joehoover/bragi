{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook demonstrates how to use `MetricGenerator`, a `Transformers` wrapper that attempts to generate song lyrics with the a specific metric structure. `MetricGenerator` allows you to specify an *initialization* song that is used to specify the target metric structure. \n",
    "\n",
    "\n",
    "`MetricGenerator` then in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97671c2c1534ba49b1d30c3940fc523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bragi.metric_generator import MetricGenerator\n",
    "from transformers import LLaMAForCausalLM, LLaMATokenizer\n",
    "import torch \n",
    "\n",
    "CACHE_DIR = 'weights'\n",
    "SEP = \"<sep>\"\n",
    "MODEL_PATH  = \"/src/weights\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "model = LLaMAForCausalLM.from_pretrained(MODEL_PATH, cache_dir=CACHE_DIR, local_files_only=True).to(device)\n",
    "tokenizer = LLaMATokenizer.from_pretrained(MODEL_PATH, cache_dir=CACHE_DIR, local_files_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use `MetricGenerator`, which is a `Transformers` wrapper that injects a logit warper that constrains the model vocabulary during generation. In theory, the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = MetricGenerator(model=model, tokenizer=tokenizer, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A song about dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---text_init----\n",
      "Happy birthday to you,\n",
      "Happy birthday to you,\n",
      "Happy birthday dear Marvin,\n",
      "Happy birthday to you\n",
      "\n",
      "\n",
      "----output-----\n",
      "I love how the dogs can \n",
      "be so good, so bad, and \n",
      "so strange. Sometimes I love them \n",
      "when they are the most good\n",
      "\n",
      "\n",
      "----Syllables-----\n",
      "Syllables per line in output: tensor([6., 6., 7., 6.])\n",
      "Syllables per line in `text_init`: tensor([6., 6., 7., 6.])\n"
     ]
    }
   ],
   "source": [
    "text_init = \"Happy birthday to you,\\nHappy birthday to you,\\nHappy birthday dear Marvin,\\nHappy birthday to you\"\n",
    "prompt = \"\"\"This is a song about dogs:\\n\"\"\"\n",
    "torch.manual_seed(2)\n",
    "output = generator.generate(\n",
    "    prompt = prompt,\n",
    "    text_init = text_init,\n",
    "    # syllable_budget = torch.Tensor([6., 6.]),\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=2,\n",
    "    remove_invalid_values=True,\n",
    "    do_sample=True,\n",
    "    top_k=25,\n",
    "    temperature=.7,\n",
    "    max_length = 100,\n",
    "    new_line_token='||',\n",
    "    free_tokens=['||', '?', '.', ','], \n",
    "    bad_words_ids=[[8876]],\n",
    ")\n",
    "\n",
    "print('---text_init----')\n",
    "print(text_init)\n",
    "print('\\n')\n",
    "\n",
    "print('----output-----')\n",
    "print(output)\n",
    "print('\\n')\n",
    "\n",
    "print('----Syllables-----')\n",
    "print(f\"Syllables per line in output: {generator.calculate_syllable_budget(output)}\")\n",
    "print(f\"Syllables per line in `text_init`: {generator.calculate_syllable_budget(text_init)}\")\n",
    "# print(tokenizer.decode(output[0], skip_special_tokens=True).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---prompt---\n",
      "This is a song about about California sun:\n",
      "\n",
      "\n",
      "---text_init----\n",
      "Happy birthday to you,\n",
      "Happy birthday to you,\n",
      "Happy birthday dear Marvin,\n",
      "Happy birthday to you\n",
      "\n",
      "\n",
      "----output-----\n",
      "I love how the colors \n",
      "the lights are bright, the air \n",
      "is warm and the water is \n",
      "clear. I love the way the\n",
      "\n",
      "\n",
      "----Syllables-----\n",
      "Syllables per line in output: tensor([6., 6., 7., 6.])\n",
      "Syllables per line in `text_init`: tensor([6., 6., 7., 6.])\n"
     ]
    }
   ],
   "source": [
    "text_init = \"Happy birthday to you,\\nHappy birthday to you,\\nHappy birthday dear Marvin,\\nHappy birthday to you\"\n",
    "prompt = \"\"\"This is a song about about California sun:\\n\"\"\"\n",
    "torch.manual_seed(2)\n",
    "output = generator.generate(\n",
    "    prompt = prompt,\n",
    "    text_init = text_init,\n",
    "    # syllable_budget = torch.Tensor([6., 6.]),\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=2,\n",
    "    remove_invalid_values=True,\n",
    "    do_sample=True,\n",
    "    top_k=25,\n",
    "    temperature=.7,\n",
    "    max_length = 100,\n",
    "    new_line_token='||',\n",
    "    free_tokens=['||', '?', '.', ','], \n",
    "    bad_words_ids=[[8876]],\n",
    ")\n",
    "\n",
    "print('---prompt---')\n",
    "print(prompt.strip())\n",
    "print('\\n')\n",
    "\n",
    "print('---text_init----')\n",
    "print(text_init)\n",
    "print('\\n')\n",
    "\n",
    "print('----output-----')\n",
    "print(output)\n",
    "print('\\n')\n",
    "\n",
    "print('----Syllables-----')\n",
    "print(f\"Syllables per line in output: {generator.calculate_syllable_budget(output)}\")\n",
    "print(f\"Syllables per line in `text_init`: {generator.calculate_syllable_budget(text_init)}\")\n",
    "# print(tokenizer.decode(output[0], skip_special_tokens=True).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---prompt---\n",
      "This a beautiful poem that uses descriptive, earthy language to describe the ocean during a storm:\n",
      "\"\n",
      "\n",
      "\n",
      "---text_init----\n",
      "Happy birthday to you,\n",
      "Happy birthday to you,\n",
      "Happy birthday dear Marvin,\n",
      "Happy birthday to you\n",
      "\n",
      "\n",
      "----output-----\n",
      "In the storm, the wind and \n",
      "the sea are one. The waves \n",
      "are the breath of the gods. As \n",
      "they break and fall back, they\n",
      "\n",
      "\n",
      "----Syllables-----\n",
      "Syllables per line in output: [6, 6, 7, 6]\n",
      "Syllables per line in `text_init`: [6, 6, 7, 6]\n"
     ]
    }
   ],
   "source": [
    "text_init = \"Happy birthday to you,\\nHappy birthday to you,\\nHappy birthday dear Marvin,\\nHappy birthday to you\"\n",
    "prompt = \"\"\"This a beautiful poem that uses descriptive, earthy language to describe the ocean during a storm:\\n\\\"\"\"\"\n",
    "torch.manual_seed(5)\n",
    "output = generator.generate(\n",
    "    prompt = prompt,\n",
    "    text_init = text_init,\n",
    "    # syllable_budget = torch.Tensor([6., 6.]),\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=2,\n",
    "    remove_invalid_values=True,\n",
    "    do_sample=True,\n",
    "    top_k=25,\n",
    "    temperature=.7,\n",
    "    max_length = 100,\n",
    "    new_line_token='||',\n",
    "    free_tokens=['||', '?', '.', ','], \n",
    "    bad_words_ids=[[8876]],\n",
    ")\n",
    "\n",
    "print('---prompt---')\n",
    "print(prompt.strip())\n",
    "print('\\n')\n",
    "\n",
    "print('---text_init----')\n",
    "print(text_init)\n",
    "print('\\n')\n",
    "\n",
    "print('----output-----')\n",
    "print(output)\n",
    "print('\\n')\n",
    "\n",
    "print('----Syllables-----')\n",
    "print(f\"Syllables per line in output: {generator.calculate_syllable_budget(output, pt=False)}\")\n",
    "print(f\"Syllables per line in `text_init`: {generator.calculate_syllable_budget(text_init, pt=False)}\")\n",
    "# print(tokenizer.decode(output[0], skip_special_tokens=True).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deviations from specified meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /root/.pyenv/versions/3.10.10/lib/python3.10/site-packages (4.65.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [05:01<00:00,  3.02s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "prompt = \"\"\"This a beautiful poem that uses descriptive, earthy language to describe the ocean during a storm:\\n\\\"\"\"\"\n",
    "text_init = \"Happy birthday to you,\\nHappy birthday to you,\\nHappy birthday dear Marvin,\\nHappy birthday to you\"\n",
    "init_syllables = generator.calculate_syllable_budget(text_init)\n",
    "\n",
    "output_syllables = []\n",
    "for i in tqdm.tqdm(range(0, 100)):\n",
    "    output = generator.generate(\n",
    "        prompt = prompt,\n",
    "        text_init = text_init,\n",
    "        # syllable_budget = torch.Tensor([6., 6.]),\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        remove_invalid_values=True,\n",
    "        do_sample=True,\n",
    "        top_k=25,\n",
    "        temperature=.7,\n",
    "        max_length = 100,\n",
    "        new_line_token='||',\n",
    "        free_tokens=['||', '?', '.', ','], \n",
    "        bad_words_ids=[[8876]],\n",
    "    )\n",
    "    \n",
    "    output_syllables.append(generator.calculate_syllable_budget(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacked_output_syllables = torch.stack(output_syllables)\n",
    "deviation = stacked_output_syllables - init_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average line-level violation of the metric constraint is -0.5174999833106995,       which suggests that the mechanism is unbiased but still flawed.\n",
      "The vast majority of deviations are within +/- 1.824031949043274 syllables of the constraint.\n"
     ]
    }
   ],
   "source": [
    "m = deviation.mean()\n",
    "std = deviation.std()\n",
    "\n",
    "print(f\"The average line-level violation of the metric constraint is {m}.\")\n",
    "print(f\"The vast majority of deviations are within +/- {std*2} syllables of the constraint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
